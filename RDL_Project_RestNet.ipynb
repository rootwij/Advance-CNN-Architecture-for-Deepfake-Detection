{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "hIz_2fDXBFAW",
    "ExecuteTime": {
     "end_time": "2025-03-10T00:17:54.507879Z",
     "start_time": "2025-03-10T00:17:54.497723Z"
    }
   },
   "source": "import os",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdYlpCv3COtB",
    "outputId": "6935fc0c-5906-4e54-dd48-3bbb5e57b7c6",
    "ExecuteTime": {
     "end_time": "2025-03-10T04:45:22.880171Z",
     "start_time": "2025-03-10T04:45:21.947051Z"
    }
   },
   "source": "!kaggle datasets download tusharpadhy/deepfake-dataset",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/tusharpadhy/deepfake-dataset\n",
      "License(s): CC0-1.0\n",
      "deepfake-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "HjUbnebJcjDT",
    "outputId": "0078fc8f-aa48-4314-97c4-6d198906cc3e",
    "ExecuteTime": {
     "end_time": "2025-03-10T04:57:10.160084Z",
     "start_time": "2025-03-10T04:49:25.640366Z"
    }
   },
   "source": [
    "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
    "dataset = 'C:/Users/rutup/OneDrive/Desktop/robust-DL/project/kaggle'\n",
    "os.makedirs(dataset, exist_ok=True)\n",
    "\n",
    "!unzip deepfake-dataset.zip -d dataset"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  deepfake-dataset.zip\n",
      "  inflating: dataset/test/Fake/00276TOPP4.jpg  \n",
      "  inflating: dataset/test/Fake/008BYSE725.jpg  \n",
      "  inflating: dataset/test/Fake/009ZTJ3621.jpg  \n",
      "  inflating: dataset/test/Fake/00F8LKY6JC.jpg  \n",
      "  inflating: dataset/test/Fake/00JEP4Z36Z.jpg  \n",
      "  inflating: dataset/test/Fake/00KEKJJ1Q4.jpg  \n",
      "  inflating: dataset/test/Fake/00MZYXAT77.jpg  \n",
      "  inflating: dataset/test/Fake/00PB1BNIE8.jpg  \n",
      "  inflating: dataset/test/Fake/00QKZTHTLF.jpg  \n",
      "  inflating: dataset/test/Fake/00V5CZZSSO.jpg  \n",
      "  inflating: dataset/test/Fake/00XUQJZGHU.jpg  \n",
      "  inflating: dataset/test/Fake/01050DBM3C.jpg  \n",
      "  inflating: dataset/test/Fake/010MNNNOZS.jpg  \n",
      "  inflating: dataset/test/Fake/017EMQKL4D.jpg  \n",
      "  inflating: dataset/test/Fake/01877XHF3A.jpg  \n",
      "  inflating: dataset/test/Fake/01EA4QAE1L.jpg  \n",
      "  inflating: dataset/test/Fake/01FCG0FF23.jpg  \n",
      "  inflating: dataset/test/Fake/01IUWPPCNT.jpg  \n",
      "  inflating: dataset/test/Fake/01KDGEL6IQ.jpg  \n",
      "  inflating: dataset/test/Fake/01MI46B2OH.jpg  \n",
      "  inflating: dataset/test/Fake/01RUCFVMJY.jpg  \n",
      "  inflating: dataset/test/Fake/025AJ3S2VH.jpg  \n",
      "  inflating: dataset/test/Fake/025TMVT114.jpg  \n",
      "  inflating: dataset/test/Fake/028M3M2AAR.jpg  \n",
      "  inflating: dataset/test/Fake/02DWMIB1T5.jpg  \n",
      "  inflating: dataset/test/Fake/02NUKFGPSJ.jpg  \n",
      "  inflating: dataset/test/Fake/02P1HEQ0GB.jpg  \n",
      "  inflating: dataset/test/Fake/02TPLQKRQB.jpg  \n",
      "  inflating: dataset/test/Fake/02XAKN4F4U.jpg  \n",
      "  inflating: dataset/test/Fake/02YD6CVUGS.jpg  \n",
      "  inflating: dataset/test/Fake/030CHMXYM3.jpg  \n",
      "  inflating: dataset/test/Fake/03G6VANLKO.jpg  \n",
      "  inflating: dataset/test/Fake/03YFLNJBI8.jpg  \n",
      "  inflating: dataset/test/Fake/040MTHBYDL.jpg  \n",
      "  inflating: dataset/test/Fake/041KW4AF4D.jpg  \n",
      "  inflating: dataset/test/Fake/0440XYKGZJ.jpg  \n",
      "  inflating: dataset/test/Fake/048F8S8DMD.jpg  \n",
      "  inflating: dataset/test/Fake/04GBOSL1AD.jpg  \n",
      "  inflating: dataset/test/Fake/04IISQZW0V.jpg  \n",
      "  inflating: dataset/test/Fake/04PV48K87K.jpg  \n",
      "  inflating: dataset/test/Fake/04U7OSKA3V.jpg  \n",
      "  inflating: dataset/test/Fake/05RDMINUOY.jpg  \n",
      "  inflating: dataset/test/Fake/05U5CQI8UO.jpg  \n",
      "  inflating: dataset/test/Fake/05W14NLKW6.jpg  \n",
      "  inflating: dataset/test/Fake/05W2PXVCGA.jpg  \n",
      "  inflating: dataset/test/Fake/05ZW9VR406.jpg  \n",
      "  inflating: dataset/test/Fake/062JK1OQH6.jpg  \n",
      "  inflating: dataset/test/Fake/063KTMQ5QZ.jpg  \n",
      "  inflating: dataset/test/Fake/069ITYSY5M.jpg  "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "4nl0NvBFc4oF",
    "outputId": "4c127c90-8877-4c99-b84a-27c168e279f3",
    "ExecuteTime": {
     "end_time": "2025-03-10T04:58:05.199260Z",
     "start_time": "2025-03-10T04:58:02.188720Z"
    }
   },
   "source": "!pip install torch torchvision",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rutup\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\rutup\\anaconda3\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\rutup\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\rutup\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rutup\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rutup\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rutup\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rutup\\anaconda3\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rutup\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rutup\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rutup\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rutup\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -eras (c:\\users\\rutup\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eras (c:\\users\\rutup\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eras (c:\\users\\rutup\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eras (c:\\users\\rutup\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eras (c:\\users\\rutup\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -eras (c:\\users\\rutup\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeFetId8c9dX",
    "outputId": "4c03d630-d885-4e39-8fb1-656ca5284027",
    "ExecuteTime": {
     "end_time": "2025-03-10T04:58:57.012727Z",
     "start_time": "2025-03-10T04:58:56.395511Z"
    }
   },
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "image_dataset = datasets.ImageFolder(root='dataset/train', transform=transform)\n",
    "\n",
    "batch_size = 256\n",
    "data_loader = DataLoader(image_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "image, label = image_dataset[0]\n",
    "print(\"Example Image Shape:\", image.shape)\n",
    "print(\"Example Label:\", label)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Image Shape: torch.Size([3, 224, 224])\n",
      "Example Label: 0\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9ljujl2dNwI",
    "outputId": "d8680d95-5852-472e-d5ad-76bffb1f4e6c",
    "ExecuteTime": {
     "end_time": "2025-03-10T04:59:40.098095Z",
     "start_time": "2025-03-10T04:59:39.382246Z"
    }
   },
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transforms for training and validation.\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Adjust these paths to match your loaded dataset\n",
    "train_dir = 'dataset/train'  # update with your training folder path\n",
    "val_dir   = 'dataset/valid'  # update with your validation folder path\n",
    "\n",
    "# Create the datasets using ImageFolder\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=val_transforms)\n",
    "\n",
    "# Print the classes to verify correct loading\n",
    "print(\"Classes found:\", train_dataset.classes)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['Fake', 'Real']\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Or_M9hoE7f_7",
    "outputId": "e43c28dd-3347-4667-bebc-fa47db22fc2f",
    "ExecuteTime": {
     "end_time": "2025-03-10T04:59:49.756347Z",
     "start_time": "2025-03-10T04:59:49.748588Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 240002\n",
      "Number of validation samples: 59428\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "6Kt7lo_j7lsE",
    "outputId": "c10a04fb-cdcc-47ef-8fde-5c469b5c0f36",
    "ExecuteTime": {
     "end_time": "2025-03-10T04:59:57.730946Z",
     "start_time": "2025-03-10T04:59:54.030064Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# Load pretrained ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers so that we only train the final layer initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected layer to output a single value (for binary classification)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(model)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rutup\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rutup\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\rutup/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:03<00:00, 33.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OfqLEAMK7pfL",
    "ExecuteTime": {
     "end_time": "2025-03-10T05:00:16.679859Z",
     "start_time": "2025-03-10T05:00:16.672226Z"
    }
   },
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# BCEWithLogitsLoss combines a sigmoid layer with binary cross entropy loss.\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Only the final layer's parameters are being optimized initially.\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=1e-4)\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KQGrCiG572pV",
    "ExecuteTime": {
     "end_time": "2025-03-10T05:02:29.818358Z",
     "start_time": "2025-03-10T05:02:29.806041Z"
    }
   },
   "source": [
    "import time, copy\n",
    "\n",
    "def train_model(model, criterion, optimizer, dataloaders, num_epochs=10, device='cuda'):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-'*10)\n",
    "\n",
    "        # Each epoch has a training and a validation phase.\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                loader = dataloaders['train']\n",
    "            else:\n",
    "                model.eval()\n",
    "                loader = dataloaders['val']\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total = 0\n",
    "\n",
    "            # Iterate over the data.\n",
    "            for inputs, labels in loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float().unsqueeze(1)  # shape: (batch_size, 1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward pass\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                total += inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / total\n",
    "            epoch_acc = running_corrects.double() / total\n",
    "\n",
    "            if phase=='train':\n",
    "                train_losses.append(epoch_loss)\n",
    "                train_accs.append(epoch_acc.item())\n",
    "            else:\n",
    "                val_losses.append(epoch_loss)\n",
    "                val_accs.append(epoch_acc.item())\n",
    "\n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Save best model weights based on validation loss.\n",
    "            if phase=='val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s')\n",
    "    print(f'Best val loss: {best_loss:.4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    history = {'train_loss': train_losses, 'val_loss': val_losses,\n",
    "               'train_acc': train_accs, 'val_acc': val_accs}\n",
    "    return model, history\n",
    "\n",
    "# Combine dataloaders into a dictionary.\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "wi97y25H7_V_",
    "outputId": "745840b6-86d6-4454-86fe-80cdf06aa958",
    "ExecuteTime": {
     "end_time": "2025-03-10T05:10:14.662994Z",
     "start_time": "2025-03-10T05:02:35.231790Z"
    }
   },
   "source": [
    "num_epochs = 5  # You can adjust this number as needed.\n",
    "model, history = train_model(model, criterion, optimizer, dataloaders,\n",
    "                             num_epochs=num_epochs, device=device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m  \u001B[38;5;66;03m# You can adjust this number as needed.\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m model, history \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [28]\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, criterion, optimizer, dataloaders, num_epochs, device)\u001B[0m\n\u001B[0;32m     44\u001B[0m         loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     45\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 47\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m inputs\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     48\u001B[0m running_corrects \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(preds \u001B[38;5;241m==\u001B[39m labels\u001B[38;5;241m.\u001B[39mdata)\n\u001B[0;32m     49\u001B[0m total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYzZsg048ZWu"
   },
   "outputs": [],
   "source": [
    "# Uncomment below to fine-tune the last block of ResNet50.\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Use a lower learning rate for fine-tuning.\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "num_epochs_ft = 5\n",
    "model, history_ft = train_model(model, criterion, optimizer_ft, dataloaders,\n",
    "                                num_epochs=num_epochs_ft, device=device)\n",
    "\n",
    "# (Optional) Merge the fine-tuning history with the initial training history.\n",
    "history['train_loss'].extend(history_ft['train_loss'])\n",
    "history['val_loss'].extend(history_ft['val_loss'])\n",
    "history['train_acc'].extend(history_ft['train_acc'])\n",
    "history['val_acc'].extend(history_ft['val_acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2DZ2ZZN8fox"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds).flatten()\n",
    "all_labels = np.array(all_labels).flatten()\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "report = classification_report(all_labels, all_preds, target_names=train_dataset.classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0kgVAKR8h6g"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=train_dataset.classes,\n",
    "            yticklabels=train_dataset.classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9ROdlne8j03"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for a Tensor.\"\"\"\n",
    "    inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std  = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Get one batch from the validation loader\n",
    "inputs, labels = next(iter(val_loader))\n",
    "inputs = inputs.to(device)\n",
    "outputs = model(inputs)\n",
    "preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy().flatten()\n",
    "labels = labels.numpy()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    pred_label = train_dataset.classes[preds[i]]\n",
    "    true_label = train_dataset.classes[labels[i]]\n",
    "    color = \"green\" if pred_label == true_label else \"red\"\n",
    "    imshow(inputs[i], title=f\"Pred: {pred_label}\\nTrue: {true_label}\")\n",
    "    plt.title(f\"Pred: {pred_label}\\nTrue: {true_label}\", color=color, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
