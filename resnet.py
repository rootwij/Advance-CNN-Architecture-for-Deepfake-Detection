# -*- coding: utf-8 -*-
"""RESNET.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zWbBIMyeSGJu9MSWiKhvKKFoBTbDEiAR
"""

!pip install -q kaggle

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download tusharpadhy/deepfake-dataset

!unzip /content/deepfake-dataset.zip

!pip install torch torchvision

import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

image_dataset = datasets.ImageFolder(root='/content/train', transform=transform)

batch_size = 256
data_loader = DataLoader(image_dataset, batch_size=batch_size, shuffle=True)


image, label = image_dataset[0]
print("Example Image Shape:", image.shape)
print("Example Label:", label)

from torchvision import datasets, transforms

# Define transforms for training and validation.
train_transforms = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

val_transforms = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# Adjust these paths to match your loaded dataset
train_dir = '/content/train'  # update with your training folder path
val_dir   = '/content/valid'  # update with your validation folder path

# Create the datasets using ImageFolder
train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)
val_dataset = datasets.ImageFolder(root=val_dir, transform=val_transforms)

# Print the classes to verify correct loading
print("Classes found:", train_dataset.classes)

from torch.utils.data import DataLoader

batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)

print(f"Number of training samples: {len(train_dataset)}")
print(f"Number of validation samples: {len(val_dataset)}")

import torch
import torch.nn as nn
from torchvision import models

# Load pretrained ResNet50
model = models.resnet50(pretrained=True)

# Freeze all layers so that we only train the final layer initially
for param in model.parameters():
    param.requires_grad = False

# Replace the final fully connected layer to output a single value (for binary classification)
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, 1)

# Move the model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
print(model)

import torch.optim as optim

# BCEWithLogitsLoss combines a sigmoid layer with binary cross entropy loss.
criterion = nn.BCEWithLogitsLoss()

# Only the final layer's parameters are being optimized initially.
optimizer = optim.Adam(model.fc.parameters(), lr=1e-4)

import time, copy

def train_model(model, criterion, optimizer, dataloaders, num_epochs=10, device='cuda'):
    since = time.time()
    best_model_wts = copy.deepcopy(model.state_dict())
    best_loss = float('inf')

    train_losses = []
    val_losses = []
    train_accs = []
    val_accs = []

    for epoch in range(num_epochs):
        print(f'Epoch {epoch+1}/{num_epochs}')
        print('-'*10)

        # Each epoch has a training and a validation phase.
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
                loader = dataloaders['train']
            else:
                model.eval()
                loader = dataloaders['val']

            running_loss = 0.0
            running_corrects = 0
            total = 0

            # Iterate over the data.
            for inputs, labels in loader:
                inputs = inputs.to(device)
                labels = labels.to(device).float().unsqueeze(1)  # shape: (batch_size, 1)

                optimizer.zero_grad()

                # forward pass
                with torch.set_grad_enabled(phase=='train'):
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    preds = (torch.sigmoid(outputs) > 0.5).float()

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
                total += inputs.size(0)

            epoch_loss = running_loss / total
            epoch_acc = running_corrects.double() / total

            if phase=='train':
                train_losses.append(epoch_loss)
                train_accs.append(epoch_acc.item())
            else:
                val_losses.append(epoch_loss)
                val_accs.append(epoch_acc.item())

            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # Save best model weights based on validation loss.
            if phase=='val' and epoch_loss < best_loss:
                best_loss = epoch_loss
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s')
    print(f'Best val loss: {best_loss:.4f}')

    # load best model weights
    model.load_state_dict(best_model_wts)

    history = {'train_loss': train_losses, 'val_loss': val_losses,
               'train_acc': train_accs, 'val_acc': val_accs}
    return model, history

# Combine dataloaders into a dictionary.
dataloaders = {'train': train_loader, 'val': val_loader}

num_epochs = 5  # You can adjust this number as needed.
model, history = train_model(model, criterion, optimizer, dataloaders,
                             num_epochs=num_epochs, device=device)

# Uncomment below to fine-tune the last block of ResNet50.

for name, param in model.named_parameters():
    if "layer4" in name or "fc" in name:
        param.requires_grad = True
    else:
        param.requires_grad = False

# Use a lower learning rate for fine-tuning.
optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)
num_epochs_ft = 5
model, history_ft = train_model(model, criterion, optimizer_ft, dataloaders,
                                num_epochs=num_epochs_ft, device=device)

# (Optional) Merge the fine-tuning history with the initial training history.
history['train_loss'].extend(history_ft['train_loss'])
history['val_loss'].extend(history_ft['val_loss'])
history['train_acc'].extend(history_ft['train_acc'])
history['val_acc'].extend(history_ft['val_acc'])

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

model.eval()
all_preds = []
all_labels = []
with torch.no_grad():
    for inputs, labels in val_loader:
        inputs = inputs.to(device)
        labels = labels.to(device).float().unsqueeze(1)
        outputs = model(inputs)
        preds = (torch.sigmoid(outputs) > 0.5).int()
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

all_preds = np.array(all_preds).flatten()
all_labels = np.array(all_labels).flatten()

cm = confusion_matrix(all_labels, all_preds)
report = classification_report(all_labels, all_preds, target_names=train_dataset.classes)
print("Confusion Matrix:")
print(cm)
print("\nClassification Report:")
print(report)

import seaborn as sns
import matplotlib.pyplot as plt


plt.figure(figsize=(4,3))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=train_dataset.classes,
            yticklabels=train_dataset.classes)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

def imshow(inp, title=None):
    """Display image for a Tensor."""
    inp = inp.cpu().numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std  = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.axis('off')

# Get one batch from the validation loader
inputs, labels = next(iter(val_loader))
inputs = inputs.to(device)
outputs = model(inputs)
preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy().flatten()
labels = labels.numpy()

plt.figure(figsize=(10,10))
for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    pred_label = train_dataset.classes[preds[i]]
    true_label = train_dataset.classes[labels[i]]
    color = "green" if pred_label == true_label else "red"
    imshow(inputs[i], title=f"Pred: {pred_label}\nTrue: {true_label}")
    plt.title(f"Pred: {pred_label}\nTrue: {true_label}", color=color, fontsize=10)
plt.tight_layout()
plt.show()